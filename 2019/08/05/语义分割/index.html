<!DOCTYPE html><html lang="en"><head><meta name="generator" content="Hexo 3.9.0"><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="description" content="语义分割学习"><meta name="keywords" content="deeplearning,语义分割"><meta name="author" content="pangzibo243"><meta name="copyright" content="pangzibo243"><title>语义分割学习 | pangzibo243's blog</title><link rel="shortcut icon" href="/melody-favicon.ico"><link rel="stylesheet" href="/css/index.css?version=1.6.1"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css?version=1.6.1"><link rel="dns-prefetch" href="https://cdn.staticfile.org"><link rel="dns-prefetch" href="https://cdn.bootcss.com"><link rel="dns-prefetch" href="https://creativecommons.org"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  }
} </script></head><body><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true"></i><div id="sidebar"><div class="toggle-sidebar-info text-center"><span data-toggle="Toggle article">Toggle site</span><hr></div><div class="sidebar-toc"><div class="sidebar-toc__title">Catalog</div><div class="sidebar-toc__progress"><span class="progress-notice">You've read</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar"></div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#什么是语义分割"><span class="toc-text">什么是语义分割</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#常用的数据集"><span class="toc-text">常用的数据集</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#评判指标"><span class="toc-text">评判指标</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#语义分割的发展历程"><span class="toc-text">语义分割的发展历程</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#FCN"><span class="toc-text">FCN</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#SegNet"><span class="toc-text">SegNet</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Dilated-Convolution"><span class="toc-text">Dilated Convolution</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#DeepLab"><span class="toc-text">DeepLab</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#RefineNet"><span class="toc-text">RefineNet</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#PSPNet"><span class="toc-text">PSPNet</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#大内核Large-Kernel-Matters"><span class="toc-text">大内核Large Kernel Matters</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Deeplabv3"><span class="toc-text">Deeplabv3</span></a></li></ol></div></div><div class="author-info hide"><div class="author-info__avatar text-center"><img src="https://raw.githubusercontent.com/litianbo243/litianbo243.github.io/master/images/my_faceQ.png"></div><div class="author-info__name text-center">pangzibo243</div><div class="author-info__description text-center">pangzibo243's blog</div><div class="follow-button"><a href="https://github.com/litianbo243">Follow Me</a></div><hr><div class="author-info-articles"><a class="author-info-articles__archives article-meta" href="/archives"><span class="pull-left">Articles</span><span class="pull-right">14</span></a><a class="author-info-articles__tags article-meta" href="/tags"><span class="pull-left">Tags</span><span class="pull-right">23</span></a><a class="author-info-articles__categories article-meta" href="/categories"><span class="pull-left">Categories</span><span class="pull-right">7</span></a></div></div></div><div id="content-outer"><div id="top-container" style="background-image: url(https://raw.githubusercontent.com/litianbo243/litianbo243.github.io/master/images/chen_sir_1.png)"><div id="page-header"><span class="pull-left"> <a id="site-name" href="/">pangzibo243's blog</a></span><i class="fa fa-bars toggle-menu pull-right" aria-hidden="true"></i><span class="pull-right menus"><a class="site-page" href="/">Home</a><a class="site-page" href="/archives">Archives</a><a class="site-page" href="/tags">Tags</a><a class="site-page" href="/categories">Categories</a></span></div><div id="post-info"><div id="post-title">语义分割学习</div><div id="post-meta"><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2019-08-05</time><span class="post-meta__separator">|</span><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/deeplearning-cv/">deeplearning_cv</a></div></div></div><div class="layout" id="content-inner"><article id="post"><div class="article-container" id="post-content"><h1 id="什么是语义分割"><a href="#什么是语义分割" class="headerlink" title="什么是语义分割"></a>什么是语义分割</h1><p>图像语义分割通俗的来讲就是，将一张图片的每个像素点进行分类，分类到每个语义，即类别。<br><img src="https://uploader.shimo.im/f/UEepmTpNxhs5caNG.png!thumbnail" alt="图片"></p>
<h1 id="常用的数据集"><a href="#常用的数据集" class="headerlink" title="常用的数据集"></a>常用的数据集</h1><p>对于深度学习来说，数据集至关重要，数据集很大程度影响最后模型的性能。现在在研究方面有几个公开的优秀数据集，大家都在这些公开的数据集上进行实验研究，相互比较来使构建的模型更优。<br>Pascal VOC 2012：有 20 类目标，这些目标包括人类、机动车类以及其他类，可用于目标类别或背景的分割<br>Cityscapes：50 个城市的城市场景语义理解数据集<br>Pascal Context：有 400 多类的室内和室外场景<br>Stanford Background Dataset：至少有一个前景物体的一组户外场景。</p>
<h1 id="评判指标"><a href="#评判指标" class="headerlink" title="评判指标"></a>评判指标</h1><p>对于一个模型来说，需要制定一个评判指标来评判这个模型是否优秀。在语义分割中，常常使用平均IOU来评判模型的性能。<br><img src="https://uploader.shimo.im/f/bYEiEffd0OYojUQE.png!thumbnail" alt="图片"><br>平均IOU是基于每个类别来计算的，即先计算每个类单独的IOU，在把每个类的IOU计算平均，就是平均IOU。<br>一般大于0.5就比较好了。</p>
<h1 id="语义分割的发展历程"><a href="#语义分割的发展历程" class="headerlink" title="语义分割的发展历程"></a>语义分割的发展历程</h1><p>2014 FCN(Fully Convolutional Networks)<br>2015 SegNet<br>2015 空洞卷积(Dilated Convolution)<br>2015 DeepLab<br>2016 RefineNet<br>2016 ENet<br>2017 PSPNet<br>2017 大内核GCN</p>
<h1 id="FCN"><a href="#FCN" class="headerlink" title="FCN"></a>FCN</h1><p>FCN的主要思想是：<br>1.几乎借鉴AlexNet的网络结构，但是把AlexNet最后几层全连接网络改成了卷积网络，这样就可以适应任意大小的图片。<br>2.使用了反卷积（上采样）将底层信息放大，采用的是将feature map周围填0，然后卷积回去，卷积过后的feature map会更大。<br>3.使用了skip结构，融合多层的特征，使结果更准确。</p>
<p>损失函数是在最后一层的 spatial map上的 pixel 的 loss 和，在每一个 pixel 使用 softmax loss 。<br>mIOU1=62.2<br>mIOU2=67.2<br><img src="https://uploader.shimo.im/f/P330llxgKPMYMaxo.png!thumbnail" alt="图片"></p>
<h1 id="SegNet"><a href="#SegNet" class="headerlink" title="SegNet"></a>SegNet</h1><p>采用encoder-decoder的思想，把图片先encoder为高维的特征，再通过decoder还原为原图的大小，其中上采样部分采用了一种叫做pooling Indices的trick。<br>在encoder时，网络经过几层卷积层后，需要max pooling层将特征图缩小，此时记录max pooling 最大元素所在的位置，叫做pooling Indices。当decoder时，进行上采样时，用pooling Indices反池化，还原成原图的大小。<br>mIOU=59.9<br><img src="https://uploader.shimo.im/f/7FKsGfFKXaggLihU.png!thumbnail" alt="图片"></p>
<h1 id="Dilated-Convolution"><a href="#Dilated-Convolution" class="headerlink" title="Dilated Convolution"></a>Dilated Convolution</h1><p>使用了空洞卷积，这是一种可用于密集预测的卷积层；<br>提出在多尺度聚集条件下使用空洞卷积的“背景模块”。<br>池化操作增大了感受野，有助于实现分类网络。但是池化操作在分割过程中也降低了分辨率。<br>因此，该论文所提出的空洞卷积层是如此工作的：<br>mIOU=71.3-75.3<br>这篇论文还是很需要看的。</p>
<p><img src="https://uploader.shimo.im/f/eqgK8TKPfbcAyTXX.png!thumbnail" alt="图片"></p>
<h1 id="DeepLab"><a href="#DeepLab" class="headerlink" title="DeepLab"></a>DeepLab</h1><p>使用了空洞卷积；<br>提出了在空间维度上实现金字塔型的空洞池化atrous spatial pyramid pooling(ASPP)；<br>使用了全连接条件随机场。<br>空洞卷积在不增加参数数量的情况下增大了感受野，按照上文提到的空洞卷积论文的做法，可以改善分割网络。<br>我们可以通过将原始图像的多个重新缩放版本传递到CNN网络的并行分支(即图像金字塔)中，或是可使用不同采样率(ASPP)的多个并行空洞卷积层，这两种方法均可实现多尺度处理。<br>我们也可通过全连接条件随机场实现结构化预测，需将条件随机场的训练和微调单独作为一个后期处理步骤。<br>mIOU=79.7<br><img src="https://uploader.shimo.im/f/WSrTPufXcvgP5QS4.png!thumbnail" alt="图片"></p>
<h1 id="RefineNet"><a href="#RefineNet" class="headerlink" title="RefineNet"></a>RefineNet</h1><p>使用空洞卷积的方法也存在一定的缺点，它的计算成本比较高，同时由于需处理大量高分辨率特征图谱，会占用大量内存，这个问题阻碍了高分辨率预测的计算研究。<br>DeepLab得到的预测结果只有原始输入的1/8大小。<br>所以，这篇论文提出了相应的编码器-解码器结构，其中编码器是ResNet-101模块，解码器为能融合编码器高分辨率特征和先前RefineNet模块低分辨率特征的RefineNet模块。<br>mIOU=84.2<br><img src="https://uploader.shimo.im/f/QjdneTyEX9EC1YFD.png!thumbnail" alt="图片"><br><img src="https://uploader.shimo.im/f/0bxTKlm16Bgvdzxq.png!thumbnail" alt="图片"></p>
<h1 id="PSPNet"><a href="#PSPNet" class="headerlink" title="PSPNet"></a>PSPNet</h1><p>全局场景分类很重要，由于它提供了分割类别分布的线索。金字塔池化模块使用大内核池化层来捕获这些信息。<br>和上文提到的空洞卷积论文一样，PSPNet也用空洞卷积来改善Resnet结构，并添加了一个金字塔池化模块。该模块将ResNet的特征图谱连接到并行池化层的上采样输出，其中内核分别覆盖了图像的整个区域、半各区域和小块区域。<br>在ResNet网络的第四阶段(即输入到金字塔池化模块后)，除了主分支的损失之外又新增了附加损失，这种思想在其他研究中也被称为中级监督(intermediate supervision)。<br>mIOU=82.6-85.4<br><img src="https://uploader.shimo.im/f/Ngb2xCs4Du4mYiyH.png!thumbnail" alt="图片"></p>
<h1 id="大内核Large-Kernel-Matters"><a href="#大内核Large-Kernel-Matters" class="headerlink" title="大内核Large Kernel Matters"></a>大内核Large Kernel Matters</h1><p>这项研究通过全局卷积网络来提高语义分割的效果。<br>语义分割不仅需要图像分割，而且需要对分割目标进行分类。在分割结构中不能使用全连接层，这项研究发现可以使用大维度内核来替代。<br>采用大内核结构的另一个原因是，尽管ResNet等多种深层网络具有很大的感受野，有相关研究发现网络倾向于在一个小得多的区域来获取信息，并提出了有效感受野的概念。<br>大内核结构计算成本高，且具有很多结构参数。因此，k×k卷积可近似成1×k＋k×1和k×1＋1×k的两种分布组合。这个模块称为全局卷积网络(Global Convolutional Network, GCN)。<br>接下来谈结构，ResNet(不带空洞卷积)组成了整个结构的编码器部分，同时GCN网络和反卷积层组成了解码器部分。该结构还使用了一种称作边界细化(Boundary Refinement，BR)的简单残差模块。<br>mIOU=82.2-83.6<br><img src="https://uploader.shimo.im/f/F1E4fJMNCP8sRP0d.png!thumbnail" alt="图片"></p>
<h1 id="Deeplabv3"><a href="#Deeplabv3" class="headerlink" title="Deeplabv3"></a>Deeplabv3</h1><p>与在DeepLab v2网络、空洞卷积中一样，这项研究也用空洞卷积/多空卷积来改善ResNet模型。<br>这篇论文还提出了三种改善ASPP的方法，涉及了像素级特征的连接、加入1×1的卷积层和三个不同比率下3×3的空洞卷积，还在每个并行卷积层之后加入了批量归一化操作。<br>级联模块实际上是一个残差网络模块，但其中的空洞卷积层是以不同比率构建的。这个模块与空洞卷积论文中提到的背景模块相似，但直接应用到中间特征图谱中，而不是置信图谱。置信图谱是指其通道数与类别数相同的CNN网络顶层特征图谱。<br>该论文独立评估了这两个所提出的模型，尝试结合将两者结合起来并没有提高实际性能。两者在验证集上的实际性能相近，带有ASPP结构的模型表现略好一些，且没有加入CRF结构。<br>这两种模型的性能优于DeepLabv2模型的最优值，文章中还提到性能的提高是由于加入了批量归一化层和使用了更优的方法来编码多尺度背景。<br>mIOU=85.7<br><img src="https://uploader.shimo.im/f/yOBoJtFSV9YzLQvB.png!thumbnail" alt="图片"></p>
</div></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">Author: </span><span class="post-copyright-info"><a href="mailto:undefined">pangzibo243</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">Link: </span><span class="post-copyright-info"><a href="https://litianbo243.github.io/2019/08/05/语义分割/">https://litianbo243.github.io/2019/08/05/语义分割/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/deeplearning/">deeplearning</a><a class="post-meta__tags" href="/tags/语义分割/">语义分割</a></div><div class="post-qr-code"><div class="post-qr-code-item"><img class="post-qr-code__img" src="https://raw.githubusercontent.com/litianbo243/litianbo243.github.io/master/images/my_zhifubao_code.png"><div class="post-qr-code__desc">支付宝打赏</div></div><div class="post-qr-code-item"><img class="post-qr-code__img" src="https://raw.githubusercontent.com/litianbo243/litianbo243.github.io/master/images/my_weixin_code.png"><div class="post-qr-code__desc">微信打赏</div></div></div><nav id="pagination"><div class="prev-post pull-left"><a href="/2019/08/05/GAN生成对抗网络学习/"><i class="fa fa-chevron-left">  </i><span>GANs生成对抗网络</span></a></div><div class="next-post pull-right"><a href="/2019/08/05/Ubuntu shell 常用指令 指南/"><span>Ubuntu常用指令</span><i class="fa fa-chevron-right"></i></a></div></nav></div></div><footer class="footer-bg" style="background-image: url(https://raw.githubusercontent.com/litianbo243/litianbo243.github.io/master/images/chen_sir_1.png)"><div class="layout" id="footer"><div class="copyright">&copy;2019 By pangzibo243</div><div class="framework-info"><span>Driven - </span><a href="http://hexo.io"><span>Hexo</span></a><span class="footer-separator">|</span><span>Theme - </span><a href="https://github.com/Molunerfinn/hexo-theme-melody"><span>Melody</span></a></div><div class="busuanzi"><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span id="busuanzi_container_page_pv"><i class="fa fa-file-o"></i><span id="busuanzi_value_page_pv"></span><span></span></span></div></div></footer><i class="fa fa-arrow-up" id="go-up" aria-hidden="true"></i><script src="https://cdn.jsdelivr.net/npm/animejs@latest/anime.min.js"></script><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@latest/velocity.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-ui-pack@latest/velocity.ui.min.js"></script><script src="/js/utils.js?version=1.6.1"></script><script src="/js/fancybox.js?version=1.6.1"></script><script src="/js/sidebar.js?version=1.6.1"></script><script src="/js/copy.js?version=1.6.1"></script><script src="/js/fireworks.js?version=1.6.1"></script><script src="/js/transition.js?version=1.6.1"></script><script src="/js/scroll.js?version=1.6.1"></script><script src="/js/head.js?version=1.6.1"></script><script>if(/Android|webOS|iPhone|iPod|BlackBerry/i.test(navigator.userAgent)) {
  $('#nav').addClass('is-mobile')
  $('footer').addClass('is-mobile')
}</script></body></html>