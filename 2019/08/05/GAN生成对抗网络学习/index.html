<!DOCTYPE html><html lang="en"><head><meta name="generator" content="Hexo 3.9.0"><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="description" content="GANs生成对抗网络"><meta name="keywords" content="deeplearning,GANs"><meta name="author" content="pangzibo243"><meta name="copyright" content="pangzibo243"><title>GANs生成对抗网络 | pangzibo243's blog</title><link rel="shortcut icon" href="/melody-favicon.ico"><link rel="stylesheet" href="/css/index.css?version=1.6.1"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css?version=1.6.1"><link rel="dns-prefetch" href="https://cdn.staticfile.org"><link rel="dns-prefetch" href="https://cdn.bootcss.com"><link rel="dns-prefetch" href="https://creativecommons.org"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  }
} </script></head><body><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true"></i><div id="sidebar"><div class="toggle-sidebar-info text-center"><span data-toggle="Toggle article">Toggle site</span><hr></div><div class="sidebar-toc"><div class="sidebar-toc__title">Catalog</div><div class="sidebar-toc__progress"><span class="progress-notice">You've read</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar"></div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#GAN的历程"><span class="toc-text">GAN的历程</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#GAN"><span class="toc-text">GAN</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#DCGAN"><span class="toc-text">DCGAN</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#ImprovedGAN"><span class="toc-text">ImprovedGAN</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#PACGAN"><span class="toc-text">PACGAN</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#WGAN"><span class="toc-text">WGAN</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#ConditionalGAN"><span class="toc-text">ConditionalGAN</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#CycleGAN"><span class="toc-text">CycleGAN</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Vid2vid"><span class="toc-text">Vid2vid</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#PGGAN"><span class="toc-text">PGGAN</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#SeqGAN"><span class="toc-text">SeqGAN</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#StackGAN"><span class="toc-text">StackGAN</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#BigGAN"><span class="toc-text">BigGAN</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#StyleGAN"><span class="toc-text">StyleGAN</span></a></li></ol></div></div><div class="author-info hide"><div class="author-info__avatar text-center"><img src="https://raw.githubusercontent.com/litianbo243/litianbo243.github.io/master/images/my_faceQ.png"></div><div class="author-info__name text-center">pangzibo243</div><div class="author-info__description text-center">pangzibo243's blog</div><div class="follow-button"><a href="https://github.com/litianbo243">Follow Me</a></div><hr><div class="author-info-articles"><a class="author-info-articles__archives article-meta" href="/archives"><span class="pull-left">Articles</span><span class="pull-right">36</span></a><a class="author-info-articles__tags article-meta" href="/tags"><span class="pull-left">Tags</span><span class="pull-right">34</span></a><a class="author-info-articles__categories article-meta" href="/categories"><span class="pull-left">Categories</span><span class="pull-right">9</span></a></div></div></div><div id="content-outer"><div id="top-container" style="background-image: url(https://raw.githubusercontent.com/litianbo243/litianbo243.github.io/master/images/chen_sir_1.png)"><div id="page-header"><span class="pull-left"> <a id="site-name" href="/">pangzibo243's blog</a></span><i class="fa fa-bars toggle-menu pull-right" aria-hidden="true"></i><span class="pull-right menus"><a class="site-page" href="/">Home</a><a class="site-page" href="/archives">Archives</a><a class="site-page" href="/tags">Tags</a><a class="site-page" href="/categories">Categories</a></span></div><div id="post-info"><div id="post-title">GANs生成对抗网络</div><div id="post-meta"><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2019-08-05</time><span class="post-meta__separator">|</span><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/deeplearning-cv/">deeplearning_cv</a></div></div></div><div class="layout" id="content-inner"><article id="post"><div class="article-container" id="post-content"><h1 id="GAN的历程"><a href="#GAN的历程" class="headerlink" title="GAN的历程"></a>GAN的历程</h1><p>左边部分主要是改进模型解决实际的图片转换，文本转图像，生成图片，视频转换等实际问题；右边部分呢则是主要解决GAN框架本身存在的一些问题。<br><img src="https://uploader.shimo.im/f/8N863gAWhQ8kKndw.png!thumbnail" alt="图片"><br>学习路径<br><img src="https://uploader.shimo.im/f/aSGbDVbi73MP3Me9.png!thumbnail" alt="图片"></p>
<h1 id="GAN"><a href="#GAN" class="headerlink" title="GAN"></a>GAN</h1><p>Ian Goodfellow 的原始 GAN 论文肯定是必读之作。涉及了GAN框架、“非饱和”损失函数以及最优判别器的推导。<br><img src="https://uploader.shimo.im/f/KDEqqQ1N1YcCx2eO.png!thumbnail" alt="图片"><br>图1：训练对抗神经网络时，同时更新判别分布（D，蓝色虚线）使D能区分数据分布px（REAL，黑色虚线）中的样本和生成分布pg(G，绿色实线) 中的样本。<br>下面的水平线为均匀采样z的区域，上面的水平线为x的部分区域。朝上的箭头显示映射x=G(z)如何将非均匀分布pg作用在转换后的样本上。G在pg高密度区域收缩，且在pg地的低密度区域扩散。<br>(a)考虑一个接近收敛的对抗的模型对：pg 与pdata相似，且D是个部分准确的分类器。<br>(b)在算法的内循环中，训练D来判断数据中的样本，收敛到D*(x)=pdata(x)/[pdata(x)+pg(x)]<br>(c)在G的一次更新后，D的梯度引导G(z)流向更可能分类为数据的区域。<br>(d)训练若干步后，如果G和D有足够的容量，他们将会接近某个点，由于pg=pdata 两者都无法提高性能。判别器将不能区别出训练数据分布和生成数据分布，即D(x)= 1/2。</p>
<h1 id="DCGAN"><a href="#DCGAN" class="headerlink" title="DCGAN"></a>DCGAN</h1><p>顾名思义，DCGAN主要讨论CNN与GAN如何结合使用并给出了一系列建议。另外还讨论了GAN特征的可视化、潜在空间插值等问题。<br><img src="https://uploader.shimo.im/f/fvnpwoL0O2kkSStY.png!thumbnail" alt="图片"></p>
<h1 id="ImprovedGAN"><a href="#ImprovedGAN" class="headerlink" title="ImprovedGAN"></a>ImprovedGAN</h1><p>Ian Goodfellow等人提供了诸多训练稳定GAN的建议，包括特征匹配、mini-batch识别、历史平均、单边标签平滑以及虚拟批标准化等技巧。讨论了GAN不稳定性的最佳假设。</p>
<h1 id="PACGAN"><a href="#PACGAN" class="headerlink" title="PACGAN"></a>PACGAN</h1><p>PACGAN讨论的是的如何分析model collapse，以及提出了PAC判别器的方法用于解决model collapse。思想其实就是将判别器的输入改成多个样本，这样判别器可以同时看到多个样本可以从一定程度上防止model collapse。</p>
<h1 id="WGAN"><a href="#WGAN" class="headerlink" title="WGAN"></a>WGAN</h1><p>WGAN首先从理论上分析了原始GAN模型存在的训练不稳定、生成器和判别器的loss无法只是训练进程、生成样本缺乏多样性等问题，并通过改进算法流程针对性的给出了改进要点。</p>
<h1 id="ConditionalGAN"><a href="#ConditionalGAN" class="headerlink" title="ConditionalGAN"></a>ConditionalGAN</h1><p>同一般形式的GAN类似，也是先训练判别网络，再训练生成网络，然后再训练判别网络，两个网络交替训练。只是训练判别网络的样本稍有不同，训练判别网络的时候需要这三种样本，分别是：<br>（1）条件和与条件相符的真实图片，期望输出为1；<br>（2）条件和与条件不符的真实图片，期望输出为0；<br>（3）条件和生成网络生成的输出，期望输出为0。</p>
<p><img src="https://uploader.shimo.im/f/l1sxGMdFOGc7BRn0.png!thumbnail" alt="图片"><br><img src="https://uploader.shimo.im/f/XQgtuFSPe1YEVygn.png!thumbnail" alt="图片"></p>
<h1 id="CycleGAN"><a href="#CycleGAN" class="headerlink" title="CycleGAN"></a>CycleGAN</h1><p>CycleGAN讨论的是image2image的转换问题，提出了Cycle consistency loss来处理缺乏成对训练样本来做image2image的转换问题。Cycle Consistency Loss 背后的主要想法，图片A转化得到图片B，再从图片B转换得到图片A’，那么图片A和图片A’应该是图一张图片。</p>
<h1 id="Vid2vid"><a href="#Vid2vid" class="headerlink" title="Vid2vid"></a>Vid2vid</h1><p>Vid2Vid通过在生成器中加入光流约束，判别器中加入光流信息以及对前景和背景分别建模重点解决了视频转换过程中前后帧图像的不一致性问题。</p>
<h1 id="PGGAN"><a href="#PGGAN" class="headerlink" title="PGGAN"></a>PGGAN</h1><p>PGGAN创造性地提出了以一种渐进增大（Progressive growing）的方式训练GAN，利用逐渐增大的PGGAN网络实现了效果令人惊叹的生成图像。“Progressive Growing” 指的是先训练 4x4 的网络，然后训练 8x8，不断增大，最终达到 1024x1024。这既加快了训练速度，又大大稳定了训练速度，并且生成的图像质量非常高。</p>
<h1 id="SeqGAN"><a href="#SeqGAN" class="headerlink" title="SeqGAN"></a>SeqGAN</h1><p>SeqGAN用对抗网络实现了离散序列数据的生成模型。解决了对抗生成网络难应用于nlp领域的问题，并且在文本生成任务上有优异表现。相比以往刻意用增强学习解决生成模型的训练不一样，在NLP上因为存在误差无法回进行梯度更新的问题，对抗生成网络的训练中只能用增强学习，所以模型结构显得如此的恰到好处。</p>
<h1 id="StackGAN"><a href="#StackGAN" class="headerlink" title="StackGAN"></a>StackGAN</h1><p>StackGAN是由文本生成图像，StackGAN模型与PGGAN工作的原理很像，StackGAN 首先输出分辨率为64×64 的图像，然后将其作为先验信息生成一个 256×256 分辨率的图像。</p>
<h1 id="BigGAN"><a href="#BigGAN" class="headerlink" title="BigGAN"></a>BigGAN</h1><p>BigGAN模型是基于 ImageNet 生成图像质量最高的模型之一。该模型很难在本地机器上实现，而且 有许多组件，如 Self-Attention、 Spectral Normalization 和带有投影鉴别器的 cGAN等。</p>
<h1 id="StyleGAN"><a href="#StyleGAN" class="headerlink" title="StyleGAN"></a>StyleGAN</h1><p>StyleGAN应该是截至目前最复杂的GAN模型，该模型借鉴了一种称为自适应实例标准化 (AdaIN) 的机制来控制潜在空间向量 z。虽然很难自己实现一个StyleGAN，但是它提供了很多有趣的想法。</p>
</div></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">Author: </span><span class="post-copyright-info"><a href="mailto:undefined">pangzibo243</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">Link: </span><span class="post-copyright-info"><a href="https://litianbo243.github.io/2019/08/05/GAN生成对抗网络学习/">https://litianbo243.github.io/2019/08/05/GAN生成对抗网络学习/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/deeplearning/">deeplearning</a><a class="post-meta__tags" href="/tags/GANs/">GANs</a></div><div class="post-qr-code"><div class="post-qr-code-item"><img class="post-qr-code__img" src="https://raw.githubusercontent.com/litianbo243/litianbo243.github.io/master/images/my_zhifubao_code.jpg"><div class="post-qr-code__desc">支付宝打赏</div></div><div class="post-qr-code-item"><img class="post-qr-code__img" src="https://raw.githubusercontent.com/litianbo243/litianbo243.github.io/master/images/my_weixin_code.jpg"><div class="post-qr-code__desc">微信打赏</div></div></div><nav id="pagination"><div class="prev-post pull-left"><a href="/2019/08/06/ssh 操作指南/"><i class="fa fa-chevron-left">  </i><span>ssh操作指南</span></a></div><div class="next-post pull-right"><a href="/2019/08/05/python 多线程、多进程/"><span>python 多线程、多进程</span><i class="fa fa-chevron-right"></i></a></div></nav></div></div><footer class="footer-bg" style="background-image: url(https://raw.githubusercontent.com/litianbo243/litianbo243.github.io/master/images/chen_sir_1.png)"><div class="layout" id="footer"><div class="copyright">&copy;2019 By pangzibo243</div><div class="framework-info"><span>Driven - </span><a href="http://hexo.io"><span>Hexo</span></a><span class="footer-separator">|</span><span>Theme - </span><a href="https://github.com/Molunerfinn/hexo-theme-melody"><span>Melody</span></a></div><div class="busuanzi"><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span id="busuanzi_container_page_pv"><i class="fa fa-file-o"></i><span id="busuanzi_value_page_pv"></span><span></span></span></div></div></footer><i class="fa fa-arrow-up" id="go-up" aria-hidden="true"></i><script src="https://cdn.jsdelivr.net/npm/animejs@latest/anime.min.js"></script><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@latest/velocity.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-ui-pack@latest/velocity.ui.min.js"></script><script src="/js/utils.js?version=1.6.1"></script><script src="/js/fancybox.js?version=1.6.1"></script><script src="/js/sidebar.js?version=1.6.1"></script><script src="/js/copy.js?version=1.6.1"></script><script src="/js/fireworks.js?version=1.6.1"></script><script src="/js/transition.js?version=1.6.1"></script><script src="/js/scroll.js?version=1.6.1"></script><script src="/js/head.js?version=1.6.1"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
    processEscapes: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
  },
  CommonHTML: {
    linebreaks: { automatic: true, width: "90% container" }
  },
  "HTML-CSS": { 
    linebreaks: { automatic: true, width: "90% container" }
  },
  "SVG": { 
    linebreaks: { automatic: true, width: "90% container" }
  }
});
</script><script type="text/x-mathjax-config">MathJax.Hub.Queue(function() {
  var all = MathJax.Hub.getAllJax(), i;
  for (i=0; i < all.length; i += 1) {
    all[i].SourceElement().parentNode.className += ' has-jax';
  }
});
</script><script src="https://cdn.jsdelivr.net/npm/mathjax/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script>if(/Android|webOS|iPhone|iPod|BlackBerry/i.test(navigator.userAgent)) {
  $('#nav').addClass('is-mobile')
  $('footer').addClass('is-mobile')
}</script></body></html>